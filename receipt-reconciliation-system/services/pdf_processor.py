import json
from llama_index.core import SimpleDirectoryReader
from models.receipt_llm_config import ReceiptExtractionLLM
from models.validation_models import ReceiptData
from pydantic import ValidationError
import logging
import re

logger = logging.getLogger(__name__)


class ReceiptPDFProcessor:
    def __init__(self):
        self.llm = ReceiptExtractionLLM()
        
        self.extraction_prompt = """
        Extract receipt information from the text below and return ONLY a valid JSON object.
        
        {
            "date": "YYYY-MM-DD",
            "vendor": "store name",
            "amount": 25.99,
            "tax": 2.50,
            "category": "category",
            "items": ["item1", "item2"],
            "payment_method": "card/cash"
        }
        
        Receipt text: {receipt_text}
        """
    
    def process_receipt(self, pdf_path: str) -> dict:
        """Process receipt, extract data, and validate it using Pydantic."""
        try:
            logger.info(f"Processing PDF: {pdf_path}")
            
            documents = SimpleDirectoryReader(input_files=[pdf_path]).load_data()
            text_content = documents[0].text
            
            logger.info(f"Extracted {len(text_content)} characters from PDF")
            
            cleaned_text = self._clean_receipt_text(text_content)
            
            if not cleaned_text or len(cleaned_text.strip()) < 10:
                logger.warning(f"Insufficient text extracted from PDF: {len(cleaned_text)} characters")
                return {'error': 'Insufficient text content in PDF', 'confidence': 0.0}
            
            prompt = self.extraction_prompt.format(receipt_text=cleaned_text)
            response = self.llm.complete(prompt)
            
            logger.info(f"LLM response received: {len(response.text)} characters")
            logger.info(f"LLM raw response: {response.text}")
            
            logger.info("ðŸš€ Bypassing JSON parsing, using direct extraction...")
            extracted_data = self._manual_json_construction(response.text)
            logger.info(f"âœ… Direct extraction successful: {extracted_data}")
            
            try:
                validated_data = ReceiptData(**extracted_data)
                validated_data_dict = validated_data.model_dump()
                validated_data_dict['confidence'] = self._calculate_confidence(validated_data_dict)
                
                logger.info(f"Successfully processed PDF with confidence: {validated_data_dict['confidence']}")
                return validated_data_dict
                
            except ValidationError as e:
                logger.error(f"Pydantic validation failed: {e}")
                logger.error(f"Extracted data: {extracted_data}")
                return {'error': f"Validation error: {e}", 'confidence': 0.0}
            
        except Exception as e:
            logger.error(f"PDF processing failed for {pdf_path}: {str(e)}")
            return {
                'error': f'PDF processing failed: {str(e)}', 
                'confidence': 0.0,
                'file_path': pdf_path
            }
        
    def _clean_receipt_text(self, text: str) -> str:
        """Clean receipt text using patterns from your data ingestion"""
        import re
        
        html_entities = {
            '&': '&', '<': '<', '>': '>', 
            '"': '"', '&#39;': "'", '&nbsp;': ' '
        }
        
        for entity, replacement in html_entities.items():
            text = text.replace(entity, replacement)
        
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'\n\s*\n+', '\n', text)
        
        return text.strip()

    def _calculate_confidence(self, extracted_data: dict) -> float:
        if not extracted_data or 'error' in extracted_data:
            return 0.0

        required_fields = ["date", "vendor", "amount"]
        score = 0.0
        
        for field in required_fields:
            if field in extracted_data and extracted_data[field] is not None:
                if isinstance(extracted_data[field], str) and extracted_data[field].strip():
                    score += 1.0
                elif isinstance(extracted_data[field], (int, float)) and extracted_data[field] > 0:
                    score += 1.0
        
        return score / len(required_fields)

    def _manual_json_construction(self, text: str) -> dict:
        """Manually construct JSON when parsing fails - ENHANCED VERSION."""
        import re
        
        logger.info("ðŸ”§ Using manual JSON construction...")
        
        result = {
            "date": "2025-08-03",
            "vendor": "Unknown Store",
            "amount": 0.0,
            "tax": 0.0,
            "category": "retail",
            "items": [],
            "payment_method": "unknown"
        }
        
        date_patterns = [
            r'\b(\d{4}-\d{2}-\d{2})\b',
            r'\b(\d{1,2}[/-]\d{1,2}[/-]\d{4})\b',
            r'\b(\d{1,2}[/-]\d{1,2}[/-]\d{2})\b',
            r'(\w{3}\s+\d{1,2},?\s+\d{4})',
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                date_str = match.group(1)
                try:
                    from datetime import datetime
                    for fmt in ['%Y-%m-%d', '%m/%d/%Y', '%m-%d-%Y', '%m/%d/%y', '%m-%d-%y']:
                        try:
                            parsed_date = datetime.strptime(date_str, fmt)
                            result["date"] = parsed_date.strftime('%Y-%m-%d')
                            break
                        except:
                            continue
                    if result["date"] != "2025-08-03":
                        break
                except:
                    result["date"] = date_str
                    break
        
        amount_patterns = [
            r'TOTAL[:\s]*\$?(\d+\.\d{2})',
            r'AMOUNT[:\s]*\$?(\d+\.\d{2})',
            r'SUBTOTAL[:\s]*\$?(\d+\.\d{2})',
            r'\$(\d+\.\d{2})\s*(?:total|amount)',
            r'\$(\d+\.\d{2})',
            r'(\d+\.\d{2})\s*(?:USD|usd|\$)',
        ]
        
        for pattern in amount_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    amount = float(match.group(1))
                    if amount > 0:
                        result["amount"] = amount
                        break
                except:
                    continue
        
        vendor_patterns = [
            r'(?:^|\n)([A-Z][A-Z\s&]{3,30})(?:\s*#|\n|Store)',
            r'(?:^|\n)([A-Za-z][A-Za-z\s&]{5,30})(?:\s*Store|\s*Market|\s*Shop)',
            r'(?:^|\n)([A-Z\s]+)(?:\s*Store|\s*Inc|\s*LLC)',
        ]
        
        for pattern in vendor_patterns:
            match = re.search(pattern, text, re.MULTILINE)
            if match:
                vendor = match.group(1).strip()
                if len(vendor) > 2 and vendor != vendor.upper():
                    result["vendor"] = vendor[:50]
                    break
        
        if result["vendor"] == "Unknown Store":
            lines = text.split('\n')[:10]
            for line in lines:
                clean_line = line.strip()
                if (len(clean_line) > 3 and 
                    not re.match(r'^\d+', clean_line) and 
                    not re.match(r'^(receipt|invoice|date|total|subtotal)', clean_line.lower())):
                    result["vendor"] = clean_line[:50]
                    break
        
        tax_patterns = [
            r'TAX[:\s]*\$?(\d+\.\d{2})',
            r'SALES TAX[:\s]*\$?(\d+\.\d{2})',
        ]
        
        for pattern in tax_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    result["tax"] = float(match.group(1))
                    break
                except:
                    continue
        
        logger.info(f"âœ… Manual construction result: {result}")
        return result
